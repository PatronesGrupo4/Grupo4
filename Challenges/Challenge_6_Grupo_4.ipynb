{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "<h2><center>Challenge 6</center></h2>"
      ],
      "metadata": {
        "id": "ErlWqGzn48rz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Librerias"
      ],
      "metadata": {
        "id": "DMpeCq0Q465s"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tc3iw6xeaePF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchvision import transforms, datasets\n",
        "from torch.utils.data import DataLoader\n",
        "from sklearn.metrics import classification_report, confusion_matrix"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Bueno (ADN intacto o mínimamente dañado): Células que tienen una cola pequeña o no visible. La mayor parte del ADN permanece dentro del núcleo, lo que sugiere que la célula tiene ADN intacto.\n",
        "\n",
        "*Malo (ADN dañado): Células que exhiben una cola pronunciada que se extiende desde el núcleo, lo que indica que el ADN se ha fragmentado, lo cual es un signo de daño.\n",
        "\n",
        "**La base de datos se separó manualmente**"
      ],
      "metadata": {
        "id": "4Um8jLE_5aye"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Rutas completas a las carpetas de datos\n",
        "train_path = r'/content/drive/MyDrive/PUCP/2023-2/Reconocimiento de Patrones/Challenge 6/train'\n",
        "test_path = r'/content/drive/MyDrive/PUCP/2023-2/Reconocimiento de Patrones/Challenge 6/test'"
      ],
      "metadata": {
        "id": "Tkwirs-T45Ij"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Código General"
      ],
      "metadata": {
        "id": "ZYCmJjxu5Opc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Definir la arquitectura de la red neuronal convolucional (CNN)\n",
        "class SimpleCNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleCNN, self).__init__()\n",
        "        # Definir capas convolucionales\n",
        "        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)\n",
        "        # Definir una capa de agrupación máxima\n",
        "        self.pool = nn.MaxPool2d(kernel_size=2, stride=2, padding=0)\n",
        "        # Capa completamente conectada (la entrada se basa en el tamaño de la imagen y el número de canales después de las capas de agrupación)\n",
        "        self.fc1 = nn.Linear(128 * 28 * 28, 512)\n",
        "        self.fc2 = nn.Linear(512, 2)  # 2 clases: buena y mala\n",
        "        # Función de activación ReLU\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Definir el paso hacia adelante a través de la red\n",
        "        x = self.pool(self.relu(self.conv1(x)))\n",
        "        x = self.pool(self.relu(self.conv2(x)))\n",
        "        x = self.pool(self.relu(self.conv3(x)))\n",
        "        x = x.view(-1, 128 * 28 * 28)  # Aplanar la capa para la entrada al FC\n",
        "        x = self.relu(self.fc1(x))\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n",
        "# Instanciar el modelo\n",
        "model = SimpleCNN()\n",
        "\n",
        "# Verificar si la GPU está disponible y mover el modelo a la GPU (ESTAMOS USANDO GPU del Colab)\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "model.to(device)\n",
        "\n",
        "# Definir la función de pérdida y el optimizador\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Definir la preprocesamiento de datos\n",
        "transform = transforms.Compose([\n",
        "    transforms.Resize((224, 224)),  # Redimensionar las imágenes a 224x224\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))  # Normalizar para cada canal\n",
        "])\n",
        "\n",
        "\n",
        "\n",
        "# Cargar los conjuntos de datos\n",
        "train_data = datasets.ImageFolder(train_path, transform=transform)\n",
        "test_data = datasets.ImageFolder(test_path, transform=transform)\n",
        "\n",
        "# Crear cargadores de datos\n",
        "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
        "test_loader = DataLoader(test_data, batch_size=32, shuffle=False)\n",
        "\n",
        "# Bucle de entrenamiento\n",
        "num_epochs = 10  # Definir el número de épocas\n",
        "for epoch in range(num_epochs):\n",
        "    model.train()\n",
        "    running_loss = 0.0\n",
        "    for data, targets in train_loader:\n",
        "        # Mover los datos al dispositivo (GPU o CPU)\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "\n",
        "        # Paso hacia adelante\n",
        "        outputs = model(data)\n",
        "        loss = criterion(outputs, targets)\n",
        "\n",
        "        # Paso hacia atrás y optimización\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Acumular la pérdida\n",
        "        running_loss += loss.item() * data.size(0)\n",
        "    # Calcular la pérdida promedio por época\n",
        "    epoch_loss = running_loss / len(train_loader.dataset)\n",
        "    print(f'Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss:.4f}')\n",
        "\n",
        "# Bucle de prueba\n",
        "model.eval()\n",
        "correct = 0\n",
        "total = 0\n",
        "\n",
        "# Reinicializar el dispositivo por si se ejecuta esta parte del código independientemente\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "model = model.to(device)\n",
        "\n",
        "# Listas para guardar predicciones y etiquetas reales\n",
        "all_preds = []\n",
        "all_targets = []\n",
        "\n",
        "# No calcular gradientes durante la prueba\n",
        "with torch.no_grad():\n",
        "    for data, targets in test_loader:\n",
        "        data, targets = data.to(device), targets.to(device)\n",
        "        outputs = model(data)\n",
        "        _, predicted = torch.max(outputs.data, 1)\n",
        "        total += targets.size(0)\n",
        "        correct += (predicted == targets).sum().item()\n",
        "        # Guardar predicciones y verdaderas etiquetas\n",
        "        all_preds.extend(predicted.cpu().numpy())\n",
        "        all_targets.extend(targets.cpu().numpy())\n",
        "\n",
        "# Calcular precisión\n",
        "accuracy = 100 * correct / total\n",
        "print(f'Precisión del modelo en imágenes de prueba: {accuracy:.2f}%')\n",
        "# Calcular y mostrar métricas adicionales\n",
        "print(classification_report(all_targets, all_preds, target_names=['bad', 'good']))\n",
        "print(confusion_matrix(all_targets, all_preds))"
      ],
      "metadata": {
        "id": "CfR8H8w0xrID",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e6036448-2a2c-4613-8fed-83373cd0958a"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/10, Loss: 2.6044\n",
            "Epoch 2/10, Loss: 1.3788\n",
            "Epoch 3/10, Loss: 0.6813\n",
            "Epoch 4/10, Loss: 0.5870\n",
            "Epoch 5/10, Loss: 0.4960\n",
            "Epoch 6/10, Loss: 0.3919\n",
            "Epoch 7/10, Loss: 0.2993\n",
            "Epoch 8/10, Loss: 0.2528\n",
            "Epoch 9/10, Loss: 0.2624\n",
            "Epoch 10/10, Loss: 0.2952\n",
            "Precisión del modelo en imágenes de prueba: 54.17%\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         bad       0.47      0.90      0.62        10\n",
            "        good       0.80      0.29      0.42        14\n",
            "\n",
            "    accuracy                           0.54        24\n",
            "   macro avg       0.64      0.59      0.52        24\n",
            "weighted avg       0.66      0.54      0.50        24\n",
            "\n",
            "[[ 9  1]\n",
            " [10  4]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        " Epochs en el Entrenamiento de Redes Neuronales\n",
        "\n",
        "Los \"epochs\" en el entrenamiento de redes neuronales se refieren a las iteraciones completas a través del conjunto completo de datos de entrenamiento. Durante un epoch, la red pasa por cada ejemplo de entrenamiento una vez, ajustando sus pesos internos a medida que intenta aprender patrones y minimizar el error de predicción.\n",
        "\n",
        "En la salida del entrenamiento mostrada, hay 10 epochs, lo que significa que el conjunto de datos completo se utilizó 10 veces para entrenar la red. Cada línea muestra el progreso después de completar un epoch, indicando que la pérdida, una medida de qué tan mal el modelo está prediciendo los datos de entrenamiento, disminuye generalmente, lo cual es indicativo de aprendizaje.\n",
        "\n",
        "La disminución de la pérdida en los datos de entrenamiento no siempre implica un mejor desempeño en datos no vistos, por eso es crucial evaluar el modelo también en un conjunto de datos de prueba.\n",
        "\n",
        "Matriz de Confusión\n",
        "\n",
        "La matriz de confusión es una herramienta para evaluar el rendimiento de un modelo de clasificación. Para dos clases ('bad' y 'good'), la matriz de 2x2 muestra:\n",
        "\n",
        "- Verdaderos positivos (VP): Instancias correctamente identificadas de una clase.\n",
        "- Falsos negativos (FN): Instancias de una clase incorrectamente identificadas como la otra clase.\n",
        "- Falsos positivos (FP): Instancias de la otra clase incorrectamente identificadas como pertenecientes a la clase en cuestión.\n",
        "- Verdaderos negativos (VN): Instancias correctamente identificadas como no pertenecientes a la clase en cuestión.\n",
        "\n",
        "Además de la matriz en sí, se derivan métricas de rendimiento como precisión, recall y F1-score, que proporcionan más detalles sobre el rendimiento del modelo en cada clase.\n"
      ],
      "metadata": {
        "id": "rrCZsr5m2sM1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "* **Verdaderos positivos (VP):** La celda superior izquierda\n",
        "(9) muestra el número de veces que el modelo predijo correctamente la clase 'bad'.\n",
        "\n",
        "* **Falsos negativos (FN):** La celda superior derecha (1) muestra el número de veces que el modelo predijo incorrectamente la clase 'good' cuando en realidad era 'bad'.\n",
        "\n",
        "* **Falsos positivos (FP):** La celda inferior izquierda (10) muestra el número de veces que el modelo predijo la clase 'bad' cuando en realidad era 'good'.\n",
        "\n",
        "* **Verdaderos negativos (VN):** La celda inferior derecha (4) muestra el número de veces que el modelo predijo correctamente la clase 'good'."
      ],
      "metadata": {
        "id": "nzEZ0JMZ2-MU"
      }
    }
  ]
}